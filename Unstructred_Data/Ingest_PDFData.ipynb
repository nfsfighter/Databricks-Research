{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67d2e58d-e4b0-4131-96c3-06024368d05f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%pip install pdfplumber pandas\n",
    "\n",
    "import pdfplumber\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract, col\n",
    " \n",
    "dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d68eb1b-ab1e-4ea0-864d-e57294c68a1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37e43d8b-6caf-46bc-87b9-986220570416",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"#row_number#\":52},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760340983986}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Define directory path\n",
    "pdf_dir = \"/Volumes/databricks_catalog/invoice_schema/pdf/PDF_Invoice_Folder/\"\n",
    "\n",
    "# Get list of all PDF files in the directory\n",
    "pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "# Extract text from each PDF file\n",
    "data = []\n",
    "for file_name in pdf_files:\n",
    "    file_path = os.path.join(pdf_dir, file_name)\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "        data.append(Row(file_name=file_name, raw_text=text))\n",
    "\n",
    "# Create a Spark DataFrame from extracted data\n",
    "pdf_df = spark.createDataFrame(data)\n",
    "\n",
    "# View the raw data\n",
    "display(pdf_df)\n",
    "\n",
    "# Extract structured fields using regex\n",
    "parsed_df = (\n",
    "    pdf_df\n",
    "    #.withColumn(\"invoice_no\", regexp_extract(\"raw_text\", r\"Invoice No:\\s*([A-Z0-9-]+)\", 1))\n",
    "    #.withColumn(\"vendor\", regexp_extract(\"raw_text\", r\"Vendor:\\s*([A-Za-z\\s&]+)\", 1))\n",
    "    #.withColumn(\"invoice_date\", regexp_extract(\"raw_text\", r\"Date:\\s*([\\d-]+)\", 1))\n",
    "    #.withColumn(\"bill_to\", regexp_extract(\"raw_text\", r\"Bill To:\\s*(.*?)\\s*-{5,}\", 1))\n",
    "    #.withColumn(\"subtotal\", regexp_extract(\"raw_text\", r\"Subtotal:\\s*([\\d,.]+)\", 1))\n",
    "    #.withColumn(\"tax\", regexp_extract(\"raw_text\", r\"Tax \\(5%\\):\\s*([\\d,.]+)\", 1))\n",
    "    #.withColumn(\"total\", regexp_extract(\"raw_text\", r\"Total Amount:\\s*([\\d,.]+)\", 1))\n",
    "    #.withColumn(\"status\", regexp_extract(\"raw_text\", r\"Payment Status:\\s*([A-Za-z]+)\", 1))\n",
    "    #.withColumn(\"address\", regexp_extract(\"raw_text\", r\"Address:.*,\\s*([\\w\\s]+,\\s*[A-Za-z]+)\", 1))\n",
    "    .withColumn(\"row_id\", regexp_extract(\"raw_text\", r\"#\\s*(\\d+)\", 1))\n",
    "    .withColumn(\"order_date\", regexp_extract(\"raw_text\", r\"Date:\\s*(\\w+\\s+\\d+\\s+\\d+)\", 1))\n",
    "    .withColumn(\"ship_mode\", regexp_extract(\"raw_text\", r\"Ship Mode:\\s*(.+?)\\s\", 1))\n",
    "    .withColumn(\"customer_name\", regexp_extract(\"raw_text\", r\"Class\\s*([\\w\\s]+?)\\s+\\d{5},\", 1))\n",
    "    .withColumn(\"address\", regexp_extract(\"raw_text\", r\"Class\\s.*\\d{4},\\s*([\\s\\S]+?)\\s*Balance\", 1))\n",
    "    .withColumn(\"postal_code\", regexp_extract(\"raw_text\", r\"Ship Mode:.*?\\n.*?\\b(\\d{5})\\b\", 1))\n",
    "    .withColumn(\"product_name\", regexp_extract(\"raw_text\", r\"Amount\\s+(.+?)\\s+\\d+\\s+\\$\", 1))\n",
    "    .withColumn(\"product_id\", regexp_extract(\"raw_text\", r\"([A-Z]{3}-[A-Z]{2}-\\d{4})\", 1))\n",
    "    .withColumn(\"category\", regexp_extract(\"raw_text\", r\"(\\bFurniture\\b)\", 1))\n",
    "    .withColumn(\"sub_category\", regexp_extract(\"raw_text\", r\"(\\bChairs\\b)\", 1))\n",
    "    .withColumn(\"quantity\", regexp_extract(\"raw_text\", r\"Amount\\s+.+?\\s+(\\d+)\\s*\\$\", 1))\n",
    "    .withColumn(\"unit_cost\", regexp_extract(\"raw_text\", r\"Amount\\s+.+?\\s+\\d+\\s*\\$(\\d+\\.\\d+)\", 1))\n",
    "    .withColumn(\"subtotal\", regexp_extract(\"raw_text\", r\"Subtotal:\\s*\\$(\\d+\\.\\d+)\", 1))\n",
    "    .withColumn(\"discount\", regexp_extract(\"raw_text\", r\"Discount.*\\$\\s*(\\d+\\.\\d+)\", 1))\n",
    "    .withColumn(\"shipping_fee\", regexp_extract(\"raw_text\", r\"Shipping:\\s*\\$(\\d+\\.\\d+)\", 1))\n",
    "    .withColumn(\"total\", regexp_extract(\"raw_text\", r\"Total:\\s*\\$(\\d+\\.\\d+)\", 1))\n",
    "    .withColumn(\"order_id\", regexp_extract(\"raw_text\", r\"Order ID\\s*:\\s*([A-Z]{2}-\\d{4}-[A-Z0-9\\-]+)\", 1))\n",
    "    .drop(\"raw_text\")\n",
    ")\n",
    "\n",
    "\n",
    "# Save structured data as Delta table (with schema merge)\n",
    "parsed_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"/Volumes/databricks_catalog/invoice_schema/datatt\")\n",
    "\n",
    "# Save as a SQL table (with schema merge)\n",
    "parsed_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"databricks_catalog.invoice_schema.raw_inovice_table\")\n",
    "\n",
    "# View & Query the structured invoice\n",
    "\n",
    "display(spark.sql(\"SELECT * FROM databricks_catalog.invoice_schema.raw_inovice_table\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingest_PDFData",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
